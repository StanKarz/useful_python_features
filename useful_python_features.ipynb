{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `map()` & `filter()`\n",
    "\n",
    "The `map()` function takes two inputs, the function to apply and the iterable (e.g. list, set, dictionary, tuple, string) to apply it to, the returned result will be an iterator, in this case, a map object containing the new output. The input function can be any callable function including built-in functions, lambda functions, user-defined functions, classes and methods. Essentially, `map()` iterates over the iterable and applies the input function to each element in the iterable, just like a for loop might do.\n",
    "\n",
    "**syntax:** `map(function, iterable)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Simple example\n",
    "\n",
    "# Define a function to calculate the square of a number\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "# Create a list of integers\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Apply the square function to each element in the map object and convert the result to a list\n",
    "squared_numbers = list(map(square, numbers))\n",
    "squared_numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Objects returned by map and filter are iterators, which means that their values aren't stored but generated as needed.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we demonstrate the use of `map()` in a typical data processing scenario common in machine learning. The goal here is to normalize a list of height data. Normalization, especially Z-score normalization, is a crucial step in preparing data for many machine-learning algorithms. It involves scaling the data so that it has a mean of 0 and a standard deviation of 1. Therefore, all features will contribute equally to the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.1121472338196007,\n",
       " -1.3137247390296034,\n",
       " 0.6889044363204011,\n",
       " 1.4899561064604028,\n",
       " -0.7529885699316021]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Example in Data Preprocessing \n",
    "\n",
    "heights = [170, 155, 180, 190, 162]\n",
    "\n",
    "# Function to calculate the mean and standard deviation\n",
    "def calculate_mean_std(data):\n",
    "    mean = sum(data) / len(data)\n",
    "    std = (sum([(x - mean) ** 2 for x in data]) / len(data)) ** 0.5\n",
    "    return mean, std\n",
    "\n",
    "mean_height, std_height = calculate_mean_std(heights)\n",
    "\n",
    "# Define a function to normalize the data\n",
    "def normalize(x):\n",
    "    return (x - mean_height) / std_height\n",
    "\n",
    "normalized_heights = list(map(normalize, heights))\n",
    "normalized_heights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`filter()` is a function that selectively passes elements from an iterable through a test function. Like `map()`, it takes a function and an iterable as arguments. However, instead of transforming each element, `filter()` checks each element against the test function and returns only those for which the function evaluates to `True`. In simple terms, `filter()` sifts through an iterable, keeping only the elements that meet a specified condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**syntax:** `filter(function, iterable)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple example\n",
    "\n",
    "def even(x):\n",
    "    return x % 2 == 0\n",
    "\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Apply the even function to each element in the filter object and convert the result to a list \n",
    "filtered_numbers = list(filter(even, numbers))\n",
    "filtered_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a machine learning context, we can use `filter()` for feature selection, data cleaning or removing outliers. For instance, we might want to filter out abnormal values which might be due to errors or outliers. These readings are crucial for training a ML model and removing them is a common preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38.888888888888886,\n",
       " 35.0,\n",
       " 38.333333333333336,\n",
       " 37.22222222222222,\n",
       " 36.666666666666664]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data: temperature readings in Fahrenheit\n",
    "sensor_readings = [102, 95, 101, 150, 99, 98, 200, 105]\n",
    "\n",
    "# Function to convert Fahrenheit readings to Celsius\n",
    "def fahrenheit_to_celsius(f):\n",
    "    return (f - 32) * 5 / 9\n",
    "\n",
    "# Function to check if the temperature is within the normal range\n",
    "def is_normal_temp(c):\n",
    "    return -5 <= c <= 40\n",
    "\n",
    "# First, convert all readings from Fahrenheit to Celsius using map\n",
    "celsius_readings = list(map(fahrenheit_to_celsius, sensor_readings))\n",
    "\n",
    "# Next, filter out abnormal readings using filter\n",
    "normal_celsius__readings = list(filter(is_normal_temp, celsius_readings))\n",
    "normal_celsius__readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, `map()` & `filter()` provide both a more Pythonic and efficient way of handling data transformations and filtering. They are considered a more elegant alternative to traditional loops, aligning with Python’s emphasis on readability and simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: <i> \"Pythonic\" </i> refers to a coding style and practice that leverages Python's unique features to write code that is clear, concise and readable. For comprehensive guidelines on adhering to these conventions refer to the __[PEP 8 Guide Style](https://peps.python.org/pep-0008/)__.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `lambda()` Functions\n",
    "\n",
    "`lambda` functions, also known as anonymous functions are defined using the `lambda` keyword and are especially useful as one-off functions that don't need to be named or reused. They are typically used where functions are required for a short period within a larger expression. They are best used sparingly and in situations where they enhance readability and conciseness. \n",
    "\n",
    "**syntax**: `lambda parameters: expression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we used both `map()` and `filter()` in conjunction with user defined functions, however we can achieve the same result using `lambda`. This approach is more concise, eliminating then need for a separate function definition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 using def\n",
    "\n",
    "# Define a function to calculate the square of a number\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "# Create a list of integers\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Apply the square function to each element in the map object and convert the result to a list\n",
    "squared_numbers_1 = list(map(square, numbers))\n",
    "\n",
    "# Method 2 using lambda\n",
    "\n",
    "squared_numbers_2 = list(map(lambda x: x ** 2, numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous example, here `lambda` performs the same check as `def_even()` within the `filter` call. This approach is more streamlined and avoids the overhead of defining and naming a separate function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 using def\n",
    "def even(x):\n",
    "    return x % 2 == 0\n",
    "\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Apply the even function to each element in the filter object and convert the result to a list \n",
    "filtered_numbers_1 = list(filter(even, numbers))\n",
    "\n",
    "# Method 2 using lambda\n",
    "filtered_numbers_2 = list(filter(lambda x: x% 2 ==0, numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the ability of `lambda` to make code more readable and expressive, particularly when utilized in common programming patterns involving `map()`, `filter()` and `sorted()`, `lambda` functions are not a one-size-fits-all solution and should be used judiciously to maintain code clarity. Here’s an example of when the use of lambda would ***not*** be appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using def \n",
    "def process_data(data):\n",
    "\t\t# Check if data is empty or None, raise an error if True\n",
    "    if not data:\n",
    "        raise ValueError(\"No data provided\")\n",
    "\t\t# Apply a complex data transformation to each data item if a condition is met\n",
    "    transformed = [complex_transformation(d) for d in data if condition(d)]\n",
    "\t\t\n",
    "\t\t# Aggregate transformed data\n",
    "    result = aggregate(transformed)\n",
    "\t\t\n",
    "\t\t#Post process aggregated result\n",
    "    post_processed_result = post_process(result)\n",
    "\n",
    "    return post_processed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using lambda\n",
    "process_data_lambda = lambda data: post_process(aggregate([complex_transformation(d) for d in data if condition(d)])) if data else ValueError(\"No data provided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. List & Dictionary Comprehensions\n",
    "\n",
    "List and dictionary comprehensions are concise ways to create lists and dictionaries in Python. They offer a more readable and efficient way to generate these collections compared to traditional loops and functions. Comprehensions follow the principle of writing simple expressions that transform or filter sequence elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**syntax**: `new_list = [expression for item in iterable if condition == True]`\n",
    "\n",
    "**syntax**: `new_dict = {key, value for key, value in iterable if condition == True}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: The `expression` can be any function or operation applied to the `item`, also the condition checking aspect of list & dict comprehensions is optional**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some simple cases, using a list comprehension with a conditional can be thought of as using `map()` and `filter()` in conjunction. As the example below shows, we are squaring all even elements in a specified range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 16]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple example\n",
    "squares = [x**2 for x in range(5) if x % 2 == 0]\n",
    "squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivalent approach using `map()` and `filter()` looks like this, it’s evident that the list comprehension is more readable and succinct, making it a preferred choice in such scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 16]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map and filter equivalent\n",
    "squares = map(lambda x: x**2, filter(lambda x: x % 2 == 0, range(5)))\n",
    "squares = list(squares)\n",
    "squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dictionary comprehension, the syntax is similar except we use curly braces `{}` instead of square brackets `[]` which are typically used for lists instead, and in this case, we omitted the optional conditional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a', 2: 'b', 3: 'c'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple example\n",
    "# Dictionary inversion, keys become values and values become keys\n",
    "\n",
    "my_map = {\"a\": 1, \"b\" :2, \"c\" : 3}\n",
    "\n",
    "inverted_map = {value: key for key, value in my_map.items()}\n",
    "inverted_map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many machine learning models, especially those based on algorithms that require numerical input, you need to convert categorical data (like color names) into numerical form. One simple approach is to create a binary encoding for a categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ML related example\n",
    "colours = ['red', 'green', 'blue', 'yellow', 'red']\n",
    "\n",
    "encoded_colours = [1 if colour == 'red' else 0 for colour in colours]\n",
    "encoded_colours "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates a simple one-hot encoding scenario. List comprehension makes it not only readable but also faster, which is crucial when encoding large datasets typical in machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'orange': 0, 'banana': 1, 'pear': 2, 'apple': 3}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ML related example\n",
    "\n",
    "categories = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n",
    "\n",
    "category_encoding = {category: idx for idx, category in enumerate(set(categories))}\n",
    "category_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, list and dictionary comprehensions are not only about writing more concise code; they also offer performance benefits. These benefits stem from the way Python optimizes comprehensions at the bytecode level. When a comprehension is compiled, Python generates specialized bytecode. This bytecode is inherently more efficient for executing loops and performing condition checks, compared to the more general-purpose bytecode generated `for` loops with embedded if-else blocks. The reason behind this efficiency is the predictable pattern of comprehensions—they consistently involve iteration and, often, condition application. This predictable structure allows Python to streamline the execution process at the bytecode level, resulting in faster performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. `Zip()`\n",
    "\n",
    "The `zip()` function accepts iterators as it's arguments and returns a zip object (an iterator of tuples) where the first item from each passed iterator is paired together, and then the second item in each passed iterator are paired together and so on until we reach the length of the iterable with the least items, this essentially decides the length of the ouput iterator. The function returns an iterator of tuples, where the i-th tuple contains the i-th element from each of the input iterators. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**syntax**: `zip(iterator_1, iterator_2, iterator_3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apple', 'red'), ('banana', 'yellow'), ('grape', 'purple')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple example pairing fruis with their colours\n",
    "\n",
    "fruits = ['apple', 'banana', 'grape', 'pear']\n",
    "colours = ['red', 'yellow', 'purple']\n",
    "\n",
    "paired_fruits = zip(fruits,colours)\n",
    "\n",
    "list(paired_fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`zip()` takes the two lists and combines them into pairs. Each pair consists of elements from the same index in each list.\n",
    "The result is an iterator of tuples, where each tuple contains one element from each of the input iterables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: There's no restriction on the number of iterators you can provide to Python's `zip()` function as input arguments.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you are working on a machine learning problem where you need to combine features from different datasets or feature sets. For instance, you might have one set of features coming from survey data and another set from transactional data, and you need to pair these features for each individual in your dataset. This is where `zip()` comes into use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey Data: (25, 'M'), Transactional Data: (1200, 300)\n",
      "Survey Data: (30, 'F'), Transactional Data: (2000, 500)\n",
      "Survey Data: (22, 'F'), Transactional Data: (1500, 400)\n"
     ]
    }
   ],
   "source": [
    "survey_features = [(25, 'M'), (30, 'F'), (22, 'F')]  # Example: (Age, Gender)\n",
    "transactional_features = [(1200, 300), (2000, 500), (1500, 400)]  # Example: (Annual Spending, Number of Transactions)\n",
    "\n",
    "# Combine features using zip\n",
    "combined_features = zip(survey_features, transactional_features)\n",
    "\n",
    "for survey, transaction in combined_features:\n",
    "    print(f\"Survey Data: {survey}, Transactional Data: {transaction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `zip()` is used to combine data from two different feature sets, creating a paired iterable.\n",
    "For each individual, you now have a tuple containing both their survey data and transactional data.\n",
    "This can be particularly useful in feature engineering, where you might need to create a unified feature set from different sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Iterators & Generators:\n",
    "     \n",
    "As previously discussed, functions like `map` and `filter` in Python return iterator objects. This ties back to our discussion on iterators, which are fundamental to Python's handling of sequences and collections. An iterator in Python is an object that can be iterated over, meaning you can traverse through all the values it holds. This is facilitated by the `__iter__()` method, which returns the iterator object itself, and the `__next__()` method, which retrieves the next value from the iterator and raises a `StopIteration` exception when there are no more values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Simple example\n",
    "\n",
    "class CountDown():\n",
    "    def __init__(self, start):\n",
    "        self.current = start\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.current <= 0:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.current -= 1\n",
    "            return self.current\n",
    "\n",
    "for number in CountDown(3):\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Iterators are particularly useful in handling large data streams that might not fit entirely in memory.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML related example\n",
    "\n",
    "class BatchIterator():\n",
    "    \"\"\"\n",
    "    An iterator that yields batches of data from a dataset.\n",
    "    This is useful in machine learning for processing large datasets in mini-batches.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index >= len(self.dataset):\n",
    "            raise StopIteration\n",
    "        batch = self.dataset[self.index:self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators are a more concise way to create iterators using functions. A generator is a function that behaves like an iterator, generating a sequence of values using the yield keyword. Unlike regular functions that return a single value and then terminate, generators can maintain state in local variables across multiple calls, making them ideal for efficient data processing, here’s some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Simple example\n",
    "\n",
    "def countdown_generator(start):\n",
    "    current = start\n",
    "    while current > 0:\n",
    "        yield current\n",
    "        current -= 1\n",
    "\n",
    "for number in countdown_generator(3):\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML related example\n",
    "\n",
    "def data_augmentation_generator(dataset, augment_func):\n",
    "    \"\"\"\n",
    "    A generator for performing data augmentation on the fly.\n",
    "    This is useful in machine learning for augmenting data during training without\n",
    "    needing to store the augmented data in memory.\n",
    "    \"\"\"\n",
    "    for data in dataset:\n",
    "        yield augment_func(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Overall**\n",
    "\n",
    "- Iterators are objects that support the iterator protocol (`__iter__` and `__next__` methods), while generators are functions that yield values using `yield`.\n",
    "- **Creation**: Iterators are created using classes, requiring explicit definitions of `__iter__` and `__next__`, whereas generators are created using functions, which is generally more concise.\n",
    "- **Use Case**: Iterators are ideal for more complex or stateful iteration, while generators are suitable for simpler cases where a function can manage the state.\n",
    "- **Commonality**: Both iterators and generators provide a way to handle large datasets efficiently, enabling the processing of data that doesn't fit in memory, and both follow lazy evaluation, computing one element at a time on demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Decorators:\n",
    "A decorator essentially takes an existing function as an argument and extends its behaviour without explicitly modifying it. Decorators are a powerful feature that allows for the modification or enhancement of functions or methods in a clean, readable and maintainable way. \n",
    "\n",
    "### Uses of Decorators:\n",
    "\n",
    "- **Code Reusability and Separation of Concerns**: Decorators can add functionality to existing functions or methods, allowing for code reuse and separation of concerns.\n",
    "- **Logging and Debugging**: They are widely used for logging function calls, which is helpful for debugging.\n",
    "- **Performance Testing**: Decorators can be used for timing functions, which is crucial in performance testing and optimisation.\n",
    "- **Data Processing and Pipeline Setup**: In data science, decorators can streamline the setup of data processing pipelines, making the code cleaner and more modular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something is happening before the function is called.\n",
      "hello!\n",
      "something is happening after the function is called.\n"
     ]
    }
   ],
   "source": [
    "def my_decorator(func):\n",
    "    def wrapper():\n",
    "        print('something is happening before the function is called.')\n",
    "        func()\n",
    "        print('something is happening after the function is called.')\n",
    "    return wrapper\n",
    "    \n",
    "\n",
    "@my_decorator\n",
    "\n",
    "def say_hello():\n",
    "    print('hello!')\n",
    "\n",
    "say_hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to execute data_processing_function: 2.002073049545288 seconds\n"
     ]
    }
   ],
   "source": [
    "# ML related example:\n",
    "\n",
    "import time\n",
    "\n",
    "def timing_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken to execute {func.__name__}: {end_time - start_time} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timing_decorator\n",
    "def data_processing_function(data):\n",
    "    # Simulate a data processing task\n",
    "    time.sleep(2)  # Sleep for 2 seconds to simulate processing\n",
    "    return [x * 2 for x in data]\n",
    "\n",
    "processed_data = data_processing_function([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning and data science, decorators have practical applications in performance monitoring, logging, and setting up data processing pipelines. By understanding and utilising decorators, you can write more efficient, cleaner, and more Pythonic code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
